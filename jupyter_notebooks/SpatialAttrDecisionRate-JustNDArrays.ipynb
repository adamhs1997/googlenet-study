{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JndnmDMp66FL"
   },
   "source": [
    "##### Copyright 2018 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "hMqWDc_m6rUC"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hOBBuzMaxU37"
   },
   "source": [
    "# Install / Import / Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UL1yOZtjqkcj"
   },
   "source": [
    "This code depends on [Lucid](https://github.com/tensorflow/lucid) (our visualization library), and [svelte](https://svelte.technology/) (a web framework). The following cell will install both of them, and dependancies such as TensorFlow. And then import them as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15298,
     "status": "ok",
     "timestamp": 1539449536510,
     "user": {
      "displayName": "Adam Horvath-Smith",
      "photoUrl": "",
      "userId": "02503422148139327677"
     },
     "user_tz": 240
    },
    "id": "AA17rJBLuyYH",
    "outputId": "4107bb2a-9a1a-44cd-d97e-42049a84cd8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/w266ajh/.local/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:104: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/w266ajh/.local/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:104: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n"
     ]
    }
   ],
   "source": [
    "#!npm install -g svelte-cli@2.2.0\n",
    "#!pip install --user scikit-image\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.misc.io import show\n",
    "import lucid.optvis.render as render\n",
    "from lucid.misc.io import show, load\n",
    "from lucid.misc.io.reading import read\n",
    "from lucid.misc.io.showing import _image_url\n",
    "from lucid.misc.gradient_override import gradient_override_map\n",
    "import lucid.scratch.web.svelte as lucid_svelte\n",
    "\n",
    "from top5gen.examples.inception_pretrained import get_top_five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cUPBCRyG9xE"
   },
   "source": [
    "# Attribution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWHqimIqk2Bs"
   },
   "outputs": [],
   "source": [
    "# This, obviously, loads up the model\n",
    "model = models.InceptionV1()\n",
    "model.load_graphdef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1539452363680,
     "user": {
      "displayName": "Adam Horvath-Smith",
      "photoUrl": "",
      "userId": "02503422148139327677"
     },
     "user_tz": 240
    },
    "id": "xIDcG0vjaDtk",
    "outputId": "c0b7cb0b-d043-45ee-acf6-90875a5cd584"
   },
   "outputs": [],
   "source": [
    "# Here we take in the 1000-dimension vector of potential image labels\n",
    "labels_str = read(\"https://gist.githubusercontent.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57/raw/aa66dd9dbf6b56649fa3fab83659b2acbf3cbfd1/map_clsloc.txt\")\n",
    "labels = [line[line.find(\" \"):].strip().encode() for line in labels_str.decode().split(\"\\n\")]\n",
    "labels = [label.decode().strip().split()[1].replace(\"_\", \" \") for label in labels]\n",
    "labels = [\"dummy\"] + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1S73WcbKIdI"
   },
   "outputs": [],
   "source": [
    "def raw_class_spatial_attr(img, layer, label, override=None):\n",
    "  \"\"\"How much did spatial positions at a given layer effect a output class?\"\"\"\n",
    "\n",
    "  # Set up a graph for doing attribution...\n",
    "  with tf.Graph().as_default(), tf.Session(), gradient_override_map(override or {}):\n",
    "    t_input = tf.placeholder_with_default(img, [None, None, 3])\n",
    "    T = render.import_model(model, t_input, t_input)\n",
    "    \n",
    "    # Compute activations\n",
    "    acts = T(layer).eval()\n",
    "    \n",
    "    # display results\n",
    "\n",
    "    \n",
    "    if label is None: return np.zeros(acts.shape[1:-1])\n",
    "    \n",
    "    # Compute gradient\n",
    "    softmax_result = T(\"softmax2_pre_activation\")\n",
    "    score = softmax_result[0, labels.index(label)] # The \"score\" is the softmax result at idx [0, label idx]\n",
    "    t_grad = tf.gradients([score], [T(layer)])[0]   \n",
    "    grad = t_grad.eval({T(layer) : acts})\n",
    "    \n",
    "    # Linear approximation of effect of spatial position\n",
    "    return np.sum(acts * grad, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_jkx5Niji4Q"
   },
   "outputs": [],
   "source": [
    "def raw_spatial_spatial_attr(img, layer1, layer2, override=None):\n",
    "  \"\"\"Attribution between spatial positions in two different layers.\"\"\"\n",
    "\n",
    "  # Set up a graph for doing attribution...\n",
    "  with tf.Graph().as_default(), tf.Session(), gradient_override_map(override or {}):\n",
    "    t_input = tf.placeholder_with_default(img, [None, None, 3])\n",
    "    T = render.import_model(model, t_input, t_input)\n",
    "    \n",
    "    # Compute activations\n",
    "    acts1 = T(layer1).eval()\n",
    "    acts2 = T(layer2).eval({T(layer1) : acts1})\n",
    "    \n",
    "    # Construct gradient tensor\n",
    "    # Backprop from spatial position (n_x, n_y) in layer2 to layer1.\n",
    "    n_x, n_y = tf.placeholder(\"int32\", []), tf.placeholder(\"int32\", [])\n",
    "    layer2_mags = tf.sqrt(tf.reduce_sum(T(layer2)**2, -1))[0]\n",
    "    score = layer2_mags[n_x, n_y]\n",
    "    t_grad = tf.gradients([score], [T(layer1)])[0]\n",
    "    \n",
    "    # Compute attribution backwards from each positin in layer2\n",
    "    attrs = []\n",
    "    for i in range(acts2.shape[1]):\n",
    "      attrs_ = []\n",
    "      for j in range(acts2.shape[2]):\n",
    "        grad = t_grad.eval({n_x : i, n_y : j, T(layer1) : acts1})\n",
    "        # linear approximation of imapct\n",
    "        attr = np.sum(acts1 * grad, -1)[0]\n",
    "        attrs_.append(attr)\n",
    "      attrs.append(attrs_)\n",
    "  return np.asarray(attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ku6hGbYmiQNI"
   },
   "source": [
    "# Spatial Attribution Interface\n",
    "\n",
    "In this section, we build the *interface* for interacting with the different kinds of spatial attribution data that we can compute using the above functions. Feel free to skip over this if you aren't interested in that part. The main reason we're including it is so that you can change the interface if you want to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1026,
     "status": "ok",
     "timestamp": 1539449544828,
     "user": {
      "displayName": "Adam Horvath-Smith",
      "photoUrl": "",
      "userId": "02503422148139327677"
     },
     "user_tz": 240
    },
    "id": "X6TFCwbQhre2",
    "outputId": "dfc9c7c0-0330-4c21-c1f6-45846d19ef06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to build svelte component from html...\n",
      "svelte compile --format iife /tmp/svelte_prc4s6qp/SpatialWidget_2d10208f_e913_4a63_a23a_f2adc3fa8b42.html > /tmp/svelte_prc4s6qp/SpatialWidget_2d10208f_e913_4a63_a23a_f2adc3fa8b42.js\n",
      "b'svelte version 1.64.1\\ncompiling ../../../tmp/svelte_prc4s6qp/SpatialWidget_2d10208f_e913_4a63_a23a_f2adc3fa8b42.html...\\n(4:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(5:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(11:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(12:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(18:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(19:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(25:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(26:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(32:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(33:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(39:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(40:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(46:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(47:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(53:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(54:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(60:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n(61:4) \\xe2\\x80\\x93 A11y: <img> element should have an alt attribute\\n'\n"
     ]
    }
   ],
   "source": [
    "%%html_define_svelte SpatialWidget\n",
    "\n",
    "<div class=\"figure\" style=\"width: 10000px; height: 250px; contain: strict;\">\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint1 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <div class=\"label\">mixed3a {{pct1}}</div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint2 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <div class=\"label\">mixed3b {{pct2}}</div>\n",
    "  </div>  \n",
    "\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint3 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <div class=\"label\">mixed4a {{pct3}}</div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint4 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <div class=\"label\">mixed4b {{pct4}}</div>\n",
    "  </div>  \n",
    "\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint5 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <div class=\"label\">mixed4c {{pct5}}</div>\n",
    "  </div>\n",
    "\n",
    " <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint6 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <div class=\"label\">mixed4d {{pct6}}</div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint6 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <div class=\"label\">mixed4e {{pct7}}</div>\n",
    "  </div>  \n",
    "\n",
    "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint8 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <div class=\"label\">mixed5a {{pct8}}</div>\n",
    "  </div>\n",
    "\n",
    "    <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
    "    <img class=\"img\"  src=\"{{img}}\">\n",
    "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint9 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
    "\n",
    "    <div class=\"label\">mixed5b {{pct9}}</div>\n",
    "  </div>\n",
    "  \n",
    "</div>\n",
    "\n",
    "\n",
    "<style>\n",
    "\n",
    "  .outer{\n",
    "    width: 224px;\n",
    "    height: 224px;\n",
    "    display: inline-block;\n",
    "    margin-right: 2px;\n",
    "    position: relative;\n",
    "  }\n",
    "  .outer img, .outer svg {\n",
    "    position: absolute;\n",
    "    left: 0px;\n",
    "    top: 0px;\n",
    "    width: 224px;\n",
    "    height: 224px;\n",
    "    image-rendering: pixelated; \n",
    "  }\n",
    "  .attr {\n",
    "    opacity: 0.6;\n",
    "  }\n",
    "  .pointer_container {\n",
    "    z-index: 100;\n",
    "  }\n",
    "  .pointer_container rect {\n",
    "    opacity: 0;\n",
    "  }\n",
    "  .pointer_container .selected  {\n",
    "    opacity: 1;\n",
    "    fill: none;\n",
    "    stroke: hsl(24, 100%, 50%);\n",
    "    stroke-width: 0.1px;\n",
    "  }\n",
    "  .label{\n",
    "    position: absolute;\n",
    "    left: 0px;\n",
    "    top: 224px;\n",
    "    width: 224px;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "  function range(n){\n",
    "    return Array(n).fill().map((_, i) => i);\n",
    "  }\n",
    "  \n",
    "  export default {\n",
    "    data () {\n",
    "      return {\n",
    "        img: \"\",\n",
    "        hint1: \"\",\n",
    "        hint2: \"\",\n",
    "        hint3: \"\",\n",
    "        hint4: \"\",\n",
    "        hint5: \"\",\n",
    "        hint6: \"\",\n",
    "        hint7: \"\",\n",
    "        hint8: \"\",\n",
    "        hint9: \"\",\n",
    "        pct1: \"\",\n",
    "        pct2: \"\",\n",
    "        pct3: \"\",\n",
    "        pct4: \"\",\n",
    "        pct5: \"\",\n",
    "        pct6: \"\",\n",
    "        pct7: \"\",\n",
    "        pct8: \"\",\n",
    "        pct9: \"\",\n",
    "        spritemap1 : \"\",\n",
    "        size1: 1,\n",
    "        spritemap2 : \"\",\n",
    "        size2: 1,\n",
    "        pos1: undefined,\n",
    "        pos2: undefined,\n",
    "        layer1: \"\",\n",
    "        layer2: \"\"\n",
    "      };\n",
    "    },\n",
    "    computed: {\n",
    "      xs1: (size1) => range(size1),\n",
    "      ys1: (size1) => range(size1),\n",
    "      xs2: (size2) => range(size2),\n",
    "      ys2: (size2) => range(size2)\n",
    "    },\n",
    "    helpers: {range}\n",
    "  };\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYaLZ6Kd2xGC"
   },
   "outputs": [],
   "source": [
    "def image_url_grid(grid):\n",
    "  return [[_image_url(img) for img in line] for line in grid ]\n",
    "\n",
    "def spatial_spatial_attr(img, layer1, layer2, hint_label_1=None, hint_label_2=None, override=None):\n",
    "  \"\"\"This is where the actual saliency maps are gen'd from the \"raw\" functions above\"\"\"\n",
    "  hint1 = orange_blue(\n",
    "      raw_class_spatial_attr(img, layer1, hint_label_1, override=override),\n",
    "      raw_class_spatial_attr(img, layer1, hint_label_2, override=override),\n",
    "      clip=True\n",
    "  )\n",
    "  hint2 = orange_blue(\n",
    "      raw_class_spatial_attr(img, layer2, hint_label_1, override=override),\n",
    "      raw_class_spatial_attr(img, layer2, hint_label_2, override=override),\n",
    "      clip=True\n",
    "  )\n",
    "\n",
    "  attrs = raw_spatial_spatial_attr(img, layer1, layer2, override=override)\n",
    "  attrs = attrs / attrs.max()\n",
    "  \n",
    "  lucid_svelte.SpatialWidget({\n",
    "    \"spritemap1\": image_url_grid(attrs),\n",
    "    \"spritemap2\": image_url_grid(attrs.transpose(2,3,0,1)),\n",
    "    \"size1\": attrs.shape[3],\n",
    "    \"layer1\": layer1,\n",
    "    \"size2\": attrs.shape[0],\n",
    "    \"layer2\": layer2,\n",
    "    \"img\" : _image_url(img),\n",
    "    \"hint1\": _image_url(hint1),\n",
    "    \"hint2\": _image_url(hint2)\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrlLGkWxKpmf"
   },
   "outputs": [],
   "source": [
    "def orange_blue(a,b,clip=False):\n",
    "  \"\"\"This is what makes the orange/blue highlights in the saliency map\"\"\"\n",
    "  \n",
    "  # Clip *is* called on each run in the given code\n",
    "  # --This appears to cut down on noise (in purple) in the final output\n",
    "  if clip:\n",
    "    a,b = np.maximum(a,0), np.maximum(b,0)\n",
    "    \n",
    "  # This is all original to what I was given, I don't know what the constants represent\n",
    "  arr = np.stack([a, (a + b)/2., b], -1)\n",
    "  arr /= 1e-2 + np.abs(arr).max()/1.5\n",
    "  arr += 0.3  # Brightens the image a tad\n",
    "  i = 0\n",
    "  j = 0\n",
    "    \n",
    "  print(type(arr))\n",
    "  print(arr.shape)\n",
    "  print(arr.size)\n",
    "  print(arr.min(), arr.max(), arr.mean())\n",
    "  print(arr[0,0])\n",
    "  return\n",
    "#   with open(\"arrdata\", 'a+') as f:\n",
    "#     for row in arr:\n",
    "#         f.write(str(row))\n",
    "#         f.write('\\n')\n",
    "  \n",
    "#   for values in arr:\n",
    "\n",
    "#     for value in values:\n",
    "\n",
    "#         for a in value:\n",
    "\n",
    "#           if a == 0.3: i += 1\n",
    "#           j += 1\n",
    "  \n",
    "  return [arr, i/j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQ1bysFVHDnL"
   },
   "source": [
    "# Simple Attribution Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load conv1_7x7_s2 weights!\n",
      "Load conv1_7x7_s2 biases!\n",
      "Load conv2_3x3_reduce weights!\n",
      "Load conv2_3x3_reduce biases!\n",
      "Load conv2_3x3 weights!\n",
      "Load conv2_3x3 biases!\n",
      "Load inception_3a_1x1 weights!\n",
      "Load inception_3a_1x1 biases!\n",
      "Load inception_3a_3x3_reduce weights!\n",
      "Load inception_3a_3x3_reduce biases!\n",
      "Load inception_3a_3x3 weights!\n",
      "Load inception_3a_3x3 biases!\n",
      "Load inception_3a_5x5_reduce weights!\n",
      "Load inception_3a_5x5_reduce biases!\n",
      "Load inception_3a_5x5 weights!\n",
      "Load inception_3a_5x5 biases!\n",
      "Load inception_3a_pool_proj weights!\n",
      "Load inception_3a_pool_proj biases!\n",
      "Load inception_3b_1x1 weights!\n",
      "Load inception_3b_1x1 biases!\n",
      "Load inception_3b_3x3_reduce weights!\n",
      "Load inception_3b_3x3_reduce biases!\n",
      "Load inception_3b_3x3 weights!\n",
      "Load inception_3b_3x3 biases!\n",
      "Load inception_3b_5x5_reduce weights!\n",
      "Load inception_3b_5x5_reduce biases!\n",
      "Load inception_3b_5x5 weights!\n",
      "Load inception_3b_5x5 biases!\n",
      "Load inception_3b_pool_proj weights!\n",
      "Load inception_3b_pool_proj biases!\n",
      "Load inception_4a_1x1 weights!\n",
      "Load inception_4a_1x1 biases!\n",
      "Load inception_4a_3x3_reduce weights!\n",
      "Load inception_4a_3x3_reduce biases!\n",
      "Load inception_4a_3x3 weights!\n",
      "Load inception_4a_3x3 biases!\n",
      "Load inception_4a_5x5_reduce weights!\n",
      "Load inception_4a_5x5_reduce biases!\n",
      "Load inception_4a_5x5 weights!\n",
      "Load inception_4a_5x5 biases!\n",
      "Load inception_4a_pool_proj weights!\n",
      "Load inception_4a_pool_proj biases!\n",
      "Load inception_4b_1x1 weights!\n",
      "Load inception_4b_1x1 biases!\n",
      "Load inception_4b_3x3_reduce weights!\n",
      "Load inception_4b_3x3_reduce biases!\n",
      "Load inception_4b_3x3 weights!\n",
      "Load inception_4b_3x3 biases!\n",
      "Load inception_4b_5x5_reduce weights!\n",
      "Load inception_4b_5x5_reduce biases!\n",
      "Load inception_4b_5x5 weights!\n",
      "Load inception_4b_5x5 biases!\n",
      "Load inception_4b_pool_proj weights!\n",
      "Load inception_4b_pool_proj biases!\n",
      "Load inception_4c_1x1 weights!\n",
      "Load inception_4c_1x1 biases!\n",
      "Load inception_4c_3x3_reduce weights!\n",
      "Load inception_4c_3x3_reduce biases!\n",
      "Load inception_4c_3x3 weights!\n",
      "Load inception_4c_3x3 biases!\n",
      "Load inception_4c_5x5_reduce weights!\n",
      "Load inception_4c_5x5_reduce biases!\n",
      "Load inception_4c_5x5 weights!\n",
      "Load inception_4c_5x5 biases!\n",
      "Load inception_4c_pool_proj weights!\n",
      "Load inception_4c_pool_proj biases!\n",
      "Load inception_4d_1x1 weights!\n",
      "Load inception_4d_1x1 biases!\n",
      "Load inception_4d_3x3_reduce weights!\n",
      "Load inception_4d_3x3_reduce biases!\n",
      "Load inception_4d_3x3 weights!\n",
      "Load inception_4d_3x3 biases!\n",
      "Load inception_4d_5x5_reduce weights!\n",
      "Load inception_4d_5x5_reduce biases!\n",
      "Load inception_4d_5x5 weights!\n",
      "Load inception_4d_5x5 biases!\n",
      "Load inception_4d_pool_proj weights!\n",
      "Load inception_4d_pool_proj biases!\n",
      "Load inception_4e_1x1 weights!\n",
      "Load inception_4e_1x1 biases!\n",
      "Load inception_4e_3x3_reduce weights!\n",
      "Load inception_4e_3x3_reduce biases!\n",
      "Load inception_4e_3x3 weights!\n",
      "Load inception_4e_3x3 biases!\n",
      "Load inception_4e_5x5_reduce weights!\n",
      "Load inception_4e_5x5_reduce biases!\n",
      "Load inception_4e_5x5 weights!\n",
      "Load inception_4e_5x5 biases!\n",
      "Load inception_4e_pool_proj weights!\n",
      "Load inception_4e_pool_proj biases!\n",
      "Load inception_5a_1x1 weights!\n",
      "Load inception_5a_1x1 biases!\n",
      "Load inception_5a_3x3_reduce weights!\n",
      "Load inception_5a_3x3_reduce biases!\n",
      "Load inception_5a_3x3 weights!\n",
      "Load inception_5a_3x3 biases!\n",
      "Load inception_5a_5x5_reduce weights!\n",
      "Load inception_5a_5x5_reduce biases!\n",
      "Load inception_5a_5x5 weights!\n",
      "Load inception_5a_5x5 biases!\n",
      "Load inception_5a_pool_proj weights!\n",
      "Load inception_5a_pool_proj biases!\n",
      "Load inception_5b_1x1 weights!\n",
      "Load inception_5b_1x1 biases!\n",
      "Load inception_5b_3x3_reduce weights!\n",
      "Load inception_5b_3x3_reduce biases!\n",
      "Load inception_5b_3x3 weights!\n",
      "Load inception_5b_3x3 biases!\n",
      "Load inception_5b_5x5_reduce weights!\n",
      "Load inception_5b_5x5_reduce biases!\n",
      "Load inception_5b_5x5 weights!\n",
      "Load inception_5b_5x5 biases!\n",
      "Load inception_5b_pool_proj weights!\n",
      "Load inception_5b_pool_proj biases!\n",
      "Load loss3_classifier weights!\n",
      "Load loss3_classifier biases!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w266ajh/.local/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/w266ajh/.local/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "/home/w266ajh/.local/lib/python3.6/site-packages/skimage/util/dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: probability: 0.89, label: paddle\n",
      "<class 'numpy.ndarray'>\n",
      "(28, 28, 3)\n",
      "2352\n",
      "0.3 1.7807576433261125 0.3263250403646833\n",
      "[0.33558258 0.31779129 0.3       ]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d7952993d16e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m               \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             )\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0msaliency_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaliency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0msaliency_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaliency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "layers = ['mixed3a', 'mixed3b', 'mixed4a', 'mixed4b', 'mixed4c', 'mixed4d', 'mixed4e', 'mixed5a', 'mixed5b']\n",
    "cur_labels = get_top_five()\n",
    "for label in cur_labels:\n",
    "    # Note: Must save the file off each time because it will not re-read raw ndarray\n",
    "    img = resize(load(label.pop(0)), (224, 224))  # Make all 224x224\n",
    "    imsave(\"current.jpeg\", img, plugin='pil', format_str='jpeg')\n",
    "    img = load(\"current.jpeg\")\n",
    "    for tag in label:\n",
    "        print(tag)\n",
    "        saliency_layers = []\n",
    "        saliency_values = []\n",
    "        for layer in layers:        \n",
    "            # Get our saliency layer\n",
    "            saliency = orange_blue(\n",
    "              raw_class_spatial_attr(img, layer, tag.split(':')[-1].strip(), override=None),\n",
    "              raw_class_spatial_attr(img, layer, None, override=None),\n",
    "              clip=True\n",
    "            )\n",
    "            saliency_layers.append(saliency[0])\n",
    "            saliency_values.append(saliency[1])\n",
    "\n",
    "            attrs = raw_spatial_spatial_attr(img, layer, \"mixed5b\", override=None)\n",
    "            attrs = attrs / attrs.max()\n",
    "\n",
    "#         lucid_svelte.SpatialWidget({\n",
    "#         \"spritemap1\": image_url_grid(attrs),\n",
    "#         \"spritemap2\": image_url_grid(attrs.transpose(2,3,0,1)),\n",
    "#         \"size1\": attrs.shape[3],\n",
    "#         \"layer1\": layer,\n",
    "#         \"size2\": attrs.shape[0],\n",
    "#         \"layer2\": layer,\n",
    "#         \"img\" : _image_url(img),\n",
    "#         \"hint1\": _image_url(saliency_layers[0]),\n",
    "#         \"hint2\": _image_url(saliency_layers[1]),\n",
    "#         \"hint3\": _image_url(saliency_layers[2]),\n",
    "#         \"hint4\": _image_url(saliency_layers[3]),\n",
    "#         \"hint5\": _image_url(saliency_layers[4]),\n",
    "#         \"hint6\": _image_url(saliency_layers[5]),\n",
    "#         \"hint7\": _image_url(saliency_layers[6]),\n",
    "#         \"hint8\": _image_url(saliency_layers[7]),\n",
    "#         \"hint9\": _image_url(saliency_layers[8]),\n",
    "#         \"pct1\": 100 - saliency_values[0] * 100,\n",
    "#         \"pct2\": 100 - saliency_values[1] * 100,\n",
    "#         \"pct3\": 100 - saliency_values[2] * 100,\n",
    "#         \"pct4\": 100 - saliency_values[3] * 100,\n",
    "#         \"pct5\": 100 - saliency_values[4] * 100,\n",
    "#         \"pct6\": 100 - saliency_values[5] * 100,\n",
    "#         \"pct7\": 100 - saliency_values[6] * 100,\n",
    "#         \"pct8\": 100 - saliency_values[7] * 100,\n",
    "#         \"pct9\": 100 - saliency_values[8] * 100\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Spatial Attribution - Building Blocks of Interpretability",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/lucid/blob/master/notebooks/building-blocks/AttrSpatial.ipynb",
     "timestamp": 1539051212813
    },
    {
     "file_id": "1uRqpBNPg-aW3tRU-uo-mWg6cQxuAquHW",
     "timestamp": 1518822563463
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
